---
layout: post
title:  "Learning what you don't know"
date:   2014-05-20 7:47AM
---

In their newest book and [a recent podcast](http://freakonomics.com/2014/05/15/the-three-hardest-words-in-the-english-language-a-new-freakonomics-radio-podcast/), the Freakonomics guys address a topic that is at once both obvious and unheard of: learning to say "I don't know." 

#### Part 1: Micro scale

They go in to some of the scenarios and reasons for not admitting ignorance (it usually boils down to not wanting to be perceived as weak), and the whole show is worth a listen, or at least [a read of the transcript](http://freakonomics.com/2014/05/15/the-three-hardest-words-in-the-english-language-full-transcript/). This idea of identifying when you do and don't know the answer to something is actually very important, and although it forms the foundation for this meditation on the topic, it deserves a moment of focus itself. 

See, that podcast has quite literally changed my life. Not 24 hours after listening to it, I was called in to a work meeting and asked a bunch of questions about the intricacies of advanced Android program interface layout that, frankly, I had no clue about. I found myself doing what we all automatically do and making hedged statements that something was "probably doable" and that something else "wouldn't been too bad" before I realized I had no idea. So I told them that I honestly didn't know, that I wouldn't waste their time hypothesizing, and that they could probably get a better answer from one of the devs with four years of experience instead of four months.

I felt embarrassed as I said it, but **I persisted because I knew that I should do it because it was the right thing to do**. The other people in the meeting weren't overjoyed that I couldn't solve **what may be unanswerable questions until you sit down and try** writing the software, but I think they understood. 

Since then, I've found that recognizing your own ignorance is actually more of a skill than I might have thought, and like all skills, **you can only practice it and never master it.** For whatever reason, the human brain has an instinct to embroider and extrapolate the answer to a question, even when asked with a woefully inadequate data set. I'm finding it takes discipline and vigilance to stop yourself and honestly say "I don't know," but it so far has worked out.

In part this is because answering virtually every question is a matter of gauging your relative confidence in an answer. Even answering a question with a definite, known, measurable answer without referring to some other source ("Which is closer to the sun: Jupiter or Saturn?") means trying to estimate how sure you are about the answer off the top of your head. I wonder how many people on the street, if you stopped them and asked them, would be willing to admit, even when it's clearly the case, that they don't know. I would guess, like the kids in Waterman's studies, most people would pick an answer and hold it fairly confidently. The answer is Jupiter, by the way. 

So it shouldn't surprise us when we take other questions that involve a foundation of fact and layer on top of it opinion and judgement that we become more likely to not back down from the challenge of an answer. In a question like the above, we already have an implicit challenge to the self-image that asks "Are you smart enough"? If you ask someone an opinion-on-top-of-facts question like "How long would this take?" question about their job, it comes with an implied question of "Are you good enough at your job?"

#### Part 2: Macro scale

This same conceit forms the basis of the classical liberal mindset. I don't know that raising the minimum wage wouldn't help people, but I don't know that it would either. 

Virtually every goverment policy involves an implicit (Hayek called it "fatal") conceit that we "know" something. That activity X is bad so we should ban or tax or restrict it. That people without X are at a disadvantage to people with it and transferring it will make things fair. That we know if we allow guns in X that more people will be shot. 

Some of these arguments are founded purely on emotion, some on studies, some on theory. But ultimately, we don't **know**, we're just guessing based on incomplete information and the urgency that we have to do **something**, just like that meeting had the urgency for me to deliver some kind of answer, even if it wasn't very good. 

Instead, what I believe that I know with pretty good confidence, borne out by enough anecdotal observations to be reliable, is that people generally do a good job of coordinating between themselves when unencumbered by government policies and government-induced monopolies. Twenty years ago, nobody knew what the internet was going to be, and during this "wild west" time of almost complete unregulation, we have seen explosive growth and dramatic gains in both profits for companies and usefulness for users (what economists call producer surplus and consumer surplus). I don't know that adding regulations to the internet would make it safer or better or fairer, but I do know that it would add compliance costs that would inevitably induce a chilling effect of at least some magnitude on innovation. 

So I stick to my guns. I don't pretend to know what the ails of society are, and encourage more people to embrace their lack of knowledge--they can keep their opinions if they want!--and hopefully let our economy be as free as possible to help us to discover the most beneficial ways to help one another.

